{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UsTy4b8gFRp"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKm3_6dLgHUI"
   },
   "outputs": [],
   "source": [
    "!pip install keras==2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgTG9-R5ODI7"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhppwagl_fVp"
   },
   "source": [
    "# Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYQ_KC4Rfu0O",
    "outputId": "490391d1-ab90-4734-e2bd-f4b0bcb65781"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import keras\n",
    "# Display Image\n",
    "from PIL import Image\n",
    "# computer vision package to read dataset\n",
    "import cv2\n",
    "import os\n",
    "from __future__ import print_function\n",
    "from keras import backend as K\n",
    "from keras import activations\n",
    "from keras import utils\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras.layers import Input\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image \n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from numpy import expand_dims\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "\n",
    "train_folder = \"/content/drive/MyDrive/train_test_val_ultrasound/train\"\n",
    "test_folder = '/content/drive/MyDrive/train_test_val_ultrasound/test'\n",
    "val_folder = '/content/drive/MyDrive/train_test_val_ultrasound/val'\n",
    "\n",
    "#train_c = os.path.join(train_folder, 'COVID-19')\n",
    "#train_n = os.path.join(train_folder , 'normal')\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, \n",
    "                                   shear_range = 0.2, zoom_range=0.2, height_shift_range=0.1,\n",
    "                                   width_shift_range=0.1,fill_mode='nearest')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(train_folder, \n",
    "                                              target_size =(224,224),\n",
    "                                              batch_size=32, \n",
    "                                              class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_folder, \n",
    "                                            target_size=(224,224),\n",
    "                                            batch_size=1, \n",
    "                                            class_mode='categorical')\n",
    "\n",
    "val_set = test_datagen.flow_from_directory(val_folder, \n",
    "                                           target_size=(224,224),\n",
    "                                           batch_size=32, \n",
    "                                           class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rt_1UhZQud41"
   },
   "source": [
    "# Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJk3FepYufxO"
   },
   "outputs": [],
   "source": [
    "#=========================================================================================================================\n",
    "#======================= NEURAL NETWORK PERFORMANCE MEASURES\n",
    "#=========================================================================================================================\n",
    "# 3.3 :: define performance evaluation functions\n",
    "\n",
    "def get_performance(conf_matrix):\n",
    "    #how many classes? = len of conf_matril\n",
    "    nos_class = len(conf_matrix[0,:]) # len of 0th row\n",
    "    res = np.zeros((0,9),dtype ='float64')\n",
    "    for i in range(0,nos_class):\n",
    "        # for each class calculate 4 performance measure - ACC, PRE, SEN, SPF, \n",
    "        # first compute TP, TN, FP, FN\n",
    "        TP = conf_matrix[i,i]\n",
    "        FP = np.sum(conf_matrix[:,i]) - TP\n",
    "        FN = np.sum(conf_matrix[i,:]) - TP\n",
    "        TN = np.sum(conf_matrix) - FN - FP - TP\n",
    "\n",
    "        ACC = (TP+TN)   /   (TP+FP+FN+TN)\n",
    "        PRE = (TP)      /   (TP+FP)\n",
    "        SEN = (TP)      /   (TP+FN)\n",
    "        SPF = (TN)      /   (TN+FP)\n",
    "        F1S = (TP)      /   (TP + (FP+FN)*0.5)\n",
    "\n",
    "        res_i = np.array([TP, FN, FP, TN, ACC, PRE, SEN, SPF, F1S])\n",
    "        res = np.vstack((res,res_i))\n",
    "    return res\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------PRINTING\n",
    "\n",
    "def print_lstr(class_labels):\n",
    "    g_LSTR=''   # HEADER ROW for printing confusing matrix\n",
    "    for i in range(0,len(class_labels)):\n",
    "        g_LSTR+='\\t'+str(class_labels[i])\n",
    "    return  g_LSTR\n",
    "\n",
    "def print_cf_row(cf_row,nos_labels):\n",
    "    res = ''\n",
    "    for j in range(0,nos_labels):\n",
    "        res += '\\t'+ str(cf_row[j])\n",
    "    return res\n",
    "def print_conf_matrix(conf_matrix, suffix, class_labels):\n",
    "    res=(suffix+'A\\\\P ' + print_lstr(class_labels)+'\\n')\n",
    "    nos_l=len(class_labels)\n",
    "    for i in range(0,nos_l):\n",
    "        res+=(suffix+str(class_labels[i]) + print_cf_row(conf_matrix[i],nos_l )+'\\n')\n",
    "    return res\n",
    "def print_performance(perf_measures, class_labels):\n",
    "    nos_class = len(perf_measures[:,0])\n",
    "\n",
    "    print('Performance for '+str(nos_class)+' classes')\n",
    "    print ('Class    \\tACC\\tPRE\\tSEN\\tSPF\\tF1S\\tALL\\tT.P\\tF.N\\tF.P\\tT.N')\n",
    "    for i in range(0, nos_class):\n",
    "        perf_i = np.round(perf_measures[i,:],2)\n",
    "        print(str(class_labels[i])+'\\t'+str(perf_i[4])+'\\t'+str(perf_i[5])+'\\t'+str(perf_i[6])+'\\t'+str(perf_i[7])+'\\t'+str(perf_i[8]) + \\\n",
    "              '\\t'+str(np.sum(perf_i[0:2]))+'\\t'+str(perf_i[0])+'\\t'+str(perf_i[1]), '\\t'+str(perf_i[2])+'\\t'+str(perf_i[3])\n",
    "              \n",
    "              )\n",
    "    return\n",
    "#------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2kn2o7mpqmh"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-7ATOwIiT63"
   },
   "outputs": [],
   "source": [
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
    "    return scale * x\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
    "\n",
    "\n",
    "def margin_loss(y_true, y_pred):\n",
    "    lamb, margin = 0.5, 0.1 \n",
    "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
    "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)\n",
    "    \n",
    "\n",
    "class Capsule(Layer):\n",
    "    def __init__(self,\n",
    "                 num_capsule,\n",
    "                 dim_capsule,\n",
    "                 routings=3, \n",
    "                 share_weights=True,\n",
    "                 activation='squash',\n",
    "                 **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'squash':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(1, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(input_num_capsule, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.share_weights:\n",
    "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
    "        else:\n",
    "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(inputs)[0]\n",
    "        input_num_capsule = K.shape(inputs)[1]\n",
    "        hat_inputs = K.reshape(hat_inputs,\n",
    "                               (batch_size, input_num_capsule,\n",
    "                                self.num_capsule, self.dim_capsule))\n",
    "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
    "\n",
    "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
    "        for i in range(self.routings):\n",
    "            c = softmax(b, 1)\n",
    "            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(o, hat_inputs, [2, 3])\n",
    "                if K.backend() == 'theano':\n",
    "                    o = K.sum(o, axis=1)\n",
    "\n",
    "        return o\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMQq4zEupzry"
   },
   "source": [
    "## build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adnJmFL9j-V2",
    "outputId": "c7c75590-32a4-4c63-c4ac-f3cd4254baab"
   },
   "outputs": [],
   "source": [
    "\n",
    "input_image = Input(shape=(224,224, 3))\n",
    "#base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=Input(shape=(224,224,3)))\n",
    "#base_model = Xception(include_top=False, weights='imagenet', input_tensor=Input(shape=(224,224,3)))\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_tensor=Input(shape=(224,224,3)))\n",
    "base_model.summary()\n",
    "\n",
    "\n",
    "vgg_out = base_model.get_layer(name = 'block5_pool').output\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "    print(layer, layer.trainable)\n",
    "\n",
    "output = Conv2D(256, kernel_size=(7,7), strides=(1, 1), activation='relu')(vgg_out)\n",
    "x = Reshape((-1, 256))(output)\n",
    "capsule = Capsule(3, 16, 3, True)(x)\n",
    "output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
    "VGGCapsnet_Binarymodel = Model(base_model.input, outputs=output)\n",
    "\n",
    "\n",
    "lr=0.00001\n",
    "VGGCapsnet_Binarymodel.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr), metrics=['accuracy'])\n",
    "\n",
    "VGGCapsnet_Binarymodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VE7C79s7qXfn"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x43CntCyqW_w"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_batch = 32\n",
    "val_batch = 16\n",
    "epochs=10\n",
    "\n",
    "filepath = '/content/drive/MyDrive/train_test_val_ultrasound/model.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False, \n",
    "                             mode='min')\n",
    "\n",
    "\n",
    "logdir = os.path.join('/content/drive/MyDrive/ultra_train_test_val/logdir',datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIg6GEgXrZPF"
   },
   "source": [
    "## start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEAqG6-yrYvu",
    "outputId": "10f76bdc-735d-4a21-a254-6430d2e7d692"
   },
   "outputs": [],
   "source": [
    "hist=VGGCapsnet_Binarymodel.fit_generator(generator = train_set,\n",
    "                    epochs=epochs,\n",
    "                    shuffle = True,\n",
    "                    validation_data=val_set, \n",
    "                    validation_steps = len(val_set.classes)//val_batch,\n",
    "                    steps_per_epoch=len(train_set.classes)//train_batch,\n",
    "                    callbacks=[checkpoint, tensorboard_callback],\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BX5P0zemrfCr"
   },
   "outputs": [],
   "source": [
    "\n",
    "#results = VGGCapsnet_Binarymodel.evaluate_generator(test_set)\n",
    "# yhat = np.argmax(VGGCapsnet_Binarymodel.predict_generator(test_set),  axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHrtR0-DtH8Q",
    "tags": []
   },
   "source": [
    "# Testing & Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9u16BREtJWo",
    "outputId": "3df818e6-cfa7-42fc-bd39-3681d7af1617",
    "tags": []
   },
   "outputs": [],
   "source": [
    "our_labels =   ['0-Covid   ', '1-Normal  ', '2-Pneumonia']\n",
    "conf_matrix = np.zeros((len(our_labels),len(our_labels)),dtype='int32') # confusion matrix Overall\n",
    "\n",
    "\n",
    "#for all_set in [test_set]: # [train_set, test_set, val_set]:\n",
    "all_set = test_set \n",
    "max_samples = len(all_set)-1\n",
    "verbose=1\n",
    "do_plot=False\n",
    "\n",
    "print('\\n++++\\n')\n",
    "print('Test samples:', max_samples+1,'of',len(all_set))\n",
    "print('\\n++++\\n')\n",
    "y_hat, y_true = [], []\n",
    "y_test, y_score = [], [] # true, pred\n",
    "\n",
    "for z,(x,y) in enumerate(all_set):\n",
    "  truth_class = np.argmax(y[0])\n",
    "\n",
    "  if do_plot:\n",
    "    plt.figure()\n",
    "    plt.imshow(x[0])\n",
    "    plt.title('Sample:'+ str(z)+'::'+str(y)+'::'+str(our_labels[truth_class]))\n",
    "    plt.show()\n",
    "    #print(i, '\\nX:', , '\\nY:', y, '\\n\\n\\n')\n",
    "  \n",
    "  \n",
    "  predicted = VGGCapsnet_Binarymodel.predict(x)\n",
    "  pred_class = np.argmax(predicted[0])\n",
    "  if verbose>0:\n",
    "    print('Sample:'+ str(z), 'True Class:', str(y), str(our_labels[truth_class]), '[predicted-class]', str(our_labels[pred_class]))\n",
    "  conf_matrix[truth_class, pred_class]+=1  # true class / pred class\n",
    "\n",
    "\n",
    "\n",
    "  yH = predicted #VGGCapsnet_Binarymodel.predict(x)\n",
    "  y_score.extend(yH)\n",
    "  y_test.extend(y)\n",
    "  yhat = np.argmax(yH, axis=1)\n",
    "  ytrue = np.argmax(y, axis=1)\n",
    "  y_hat.extend(yhat)\n",
    "  y_true.extend(ytrue)\n",
    "# end for\n",
    "\n",
    "\n",
    "  if z==max_samples: \n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "y_hat, y_true = np.array(y_hat), np.array(y_true)\n",
    "y_test, y_score =  np.array(y_test),  np.array(y_score)\n",
    "#print(y_test)\n",
    "#print(y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZDjx1mL-tTd",
    "tags": []
   },
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oc1fqWa3uZI5",
    "outputId": "99e82579-92ce-49dc-d05b-b48bf1f45f30",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('\\tGlobal Confusion Matrix [Overall]')\n",
    "print(print_conf_matrix( conf_matrix,'', our_labels)) #logit('\\t'+str(cmx))\n",
    "print_performance( get_performance(conf_matrix) ,our_labels ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri0wfGWh-wZt",
    "tags": []
   },
   "source": [
    "## Performace (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 733
    },
    "id": "D_zT0IEKeWzc",
    "outputId": "a1b304c2-7e93-4a11-9dd8-e288adb41e7e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "ytest, yhat = y_true, y_hat\n",
    "print(classification_report(ytest, yhat))\n",
    "cf_matrix = confusion_matrix(ytest, yhat)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf_matrix, annot = True, ax=ax,fmt = \".1f\")\n",
    "plt.ylabel('Actal Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['COVID-19', 'Normal', 'Pneumonia']); ax.yaxis.set_ticklabels(['COVID-19', 'Normal', 'Pneumonia']);\n",
    "# our_labels =   ['0-Covid   ', '1-Normal  ', '2-Pneumonia']\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvTa5f-M-TOt",
    "tags": []
   },
   "source": [
    "# Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "GlA-MUpforR5",
    "outputId": "1aae413d-a468-4669-f83d-4566eac40a02",
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = hist.history['acc']\n",
    "val_accuracy = hist.history['val_acc']\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, accuracy, 'go-', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'ms-', label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "x80L0DcJqFMt",
    "outputId": "94a36d8f-0e59-4475-992d-06a990f11e8b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, accuracy, 'go-', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'ms-', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy curves for VGGCapsNet Model')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo-', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'rs-', label='Validation loss')\n",
    "plt.title('Training and validation loss curves for VGGCapsNet Model')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.savefig('foo.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_NTE5ZfM0O3",
    "tags": []
   },
   "source": [
    "# RoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "w0nQn_EUWDLX",
    "outputId": "1b2bfb52-97b1-4a79-dc02-781c53a39b68",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "n_classes = 3\n",
    "#y_test, y_score = y_true, y_hat\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                                   ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.savefig('line_plot.jpg', dpi=300, quality=80, optimize=True, progressive=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[0]_CNET.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
